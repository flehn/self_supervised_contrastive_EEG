{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b018bf-9fe9-4512-a1b2-06b8bc5a5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different EEG Augmentation functions\n",
    "#!git clone https://github.com/braindecode/braindecode.git\n",
    "\n",
    "#TorchEEG manuell import:\n",
    "#!git clone https://github.com/torcheeg/torcheeg.git\n",
    "\n",
    "#SimCLR TorchEEG:\n",
    "#https://torcheeg.readthedocs.io/en/latest/generated/torcheeg.trainers.SimCLRTrainer.html#torcheeg.trainers.SimCLRTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bff31f0-feb4-4739-9b81-e129d149d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d1c0e5-0d7b-4704-9b04-f944f4caf66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data_paths\n",
    "DATA_PATH = './' #where data is saved\n",
    "TMP_DATA = './Tmp_Datasets'\n",
    "CHECKPOINT_PATH = './saved_models' # Path to the folder where the pretrained models are saved\n",
    "\n",
    "# Path to the folder where the training dataset is located\n",
    "SEED_PATH = './SEED/SEED_EEG/ExtractedFeatures/Subj'\n",
    "SEEDiv_PATH = './SEED/SEED_IV/ExtractedFeatures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20bf9ed-55a9-49bf-b107-9e11db3ee899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_WORKERS: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 13:45:05,220 DEBUG MainThread git.cmd Popen(['git', 'version'], cwd=/workspace, stdin=None, shell=False, universal_newlines=False)\n",
      "2023-12-05 13:45:05,224 DEBUG MainThread git.cmd Popen(['git', 'version'], cwd=/workspace, stdin=None, shell=False, universal_newlines=False)\n",
      "2023-12-05 13:45:05,238 DEBUG MainThread wandb.docker.auth Trying paths: ['/root/.docker/config.json', '/root/.dockercfg']\n",
      "2023-12-05 13:45:05,240 DEBUG MainThread wandb.docker.auth No config file found\n",
      "2023-12-05 13:45:05,297 DEBUG MainThread sentry_sdk.errors [Tracing] Create new propagation context: {'trace_id': 'b84c24e16ad1450fa1db9b5daf86aef0', 'span_id': 'ab621656937cc10d', 'parent_span_id': None, 'dynamic_sampling_context': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  5 13:45:05 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A40                     On  | 00000000:52:00.0 Off |                    0 |\n",
      "|  0%   31C    P8              21W / 300W |      4MiB / 46068MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "Your runtime has 540.7 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n",
      "Is the GPU available? True\n",
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "gpus = [0]\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(map(str, gpus))\n",
    "print(f'NUM_WORKERS: {NUM_WORKERS}')\n",
    "\n",
    "import numpy as np\n",
    "import io\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "#Import Pytorch\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch.nn.functional import pad\n",
    "    from torch import Tensor\n",
    "    from torch.fft import fft, ifft\n",
    "    import torch.optim as optim\n",
    "    import sklearn\n",
    "    import seaborn \n",
    "\n",
    "except ModuleNotFoundError: \n",
    "    !pip install seaborn \n",
    "    !pip install torch\n",
    "    !pip install scikit-learn\n",
    "    import seaborn \n",
    "    import sklearn\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch.nn.functional import pad\n",
    "    from torch import Tensor\n",
    "    import torch.optim as optim\n",
    "    from torch.fft import fft, ifft\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import lightning.pytorch as pl\n",
    "    #import pytorch_lightning as pl\n",
    "    import torchmetrics\n",
    "    import torcheeg\n",
    "    import wandb\n",
    "    \n",
    "\n",
    "except ModuleNotFoundError: \n",
    "    !pip install wandb\n",
    "    !pip install comet-ml\n",
    "    !pip install lightning\n",
    "    #!pip install --quiet pytorch-lightning>=1.4\n",
    "    !pip install torcheeg\n",
    "    !pip install torchmetrics\n",
    "    import wandb\n",
    "    #import comet_ml\n",
    "    import lightning.pytorch as pl\n",
    "    #import pytorch_lightning as pl\n",
    "    import torcheeg\n",
    "    import torchmetrics\n",
    "\n",
    "\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.loggers import CometLogger\n",
    "from lightning.pytorch.callbacks import GradientAccumulationScheduler, LearningRateMonitor, ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "#from pytorch_lightning.loggers import WandbLogger\n",
    "#from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "\n",
    "from typing import Any, Tuple, List\n",
    "from torcheeg.datasets import SEEDDataset, DEAPDataset\n",
    "from torcheeg import transforms, model_selection\n",
    "\n",
    "\n",
    "#Create custom dataset:(inherits from torch.utils.data.Dataset)\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "import scipy\n",
    "import scipy.io as scio #for loading raw EEG\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "import PIL\n",
    "\n",
    "from matplotlib import colors\n",
    "from mne.viz import circular_layout\n",
    "from mne_connectivity.viz import plot_connectivity_circle\n",
    "from pylab import cm\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "#Local imports \n",
    "#from Plotting import PlotEEG\n",
    "#from Datasets import create_dataset\n",
    "from AllModels import *\n",
    "#from Augmentations import ContrastiveTransformations\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')\n",
    "\n",
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1439d840-b7e9-40ac-b3e1-b7e715d64964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Parameter\n",
    "'''\n",
    "\n",
    "#EEG - Data:\n",
    "chunk_size=200 #length of a sample\n",
    "channels = 62\n",
    "overlap=0 \n",
    "\n",
    "#NonSSL Models:\n",
    "nr_devices = 'auto'\n",
    "batch_size=64\n",
    "nr_classes=3 #Number of target classes\n",
    "nr_epochs=30\n",
    "lr=4e-4  # Conformer paper uses 0.0002\n",
    "weight_decay=1e-3\n",
    "\n",
    "#SSL-only Model\n",
    "batch_sizeSSL = 1024 #based on https://arxiv.org/pdf/2002.05709.pdf\n",
    "lrSSL= 5e-4 #0.0001 \n",
    "weight_decaySSL = 1e-6 #based on https://arxiv.org/pdf/2002.05709.pdf\n",
    "temperatureSSL = 0.05 #based on mohsenvand2020a\n",
    "nr_epochs_ssl=100 \n",
    "\n",
    "#https://arxiv.org/pdf/2007.16104.pdf\n",
    "#The Adam optimizer [50] with β1 = 0.9 and β2 = 0.999 and learning rate 5 × 10−4 was used.\n",
    "\n",
    "#https://arxiv.org/pdf/2109.09559.pdf\n",
    "#We used an Adam optimizer [85] with a cosine annealing learning rate scheduler and a three-time warm restart [86]. \n",
    "#The initial learning rate was set to 0.0007, and the weight decay was set to 0.015 empirically. \n",
    "'''\n",
    "In the contrastive learning procedure, we used stratified\n",
    "normalization [84] during training. In stratified normalization, we concatenated the same channel of different samples from one subject in the minibatch together and conducted z-score normalization. The stratified normalization\n",
    "was applied to inputs of the base encoder, outputs of average pooling, and outputs of the temporal convolution in\n",
    "the projector. F\n",
    "'''\n",
    "\n",
    "if str(device).startswith(\"cuda\"):\n",
    "    torch.set_float32_matmul_precision('high') #Increase performance\n",
    "    \n",
    "#Logger\n",
    "project_name='Experiment_11'\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "\n",
    "#198d0b46f74d1861672c12c46489054b043161f2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a339bf7-eaf6-43bc-bcef-01db2979de06",
   "metadata": {},
   "source": [
    "##SimCLR Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc513656-a3a9-4b16-9738-8cf60444f847",
   "metadata": {},
   "source": [
    "## PreTrext Task\n",
    "\n",
    "The Pretext task is using contrastive learning with the Conformer as encoder, which creates vector representations of the eeg input. Those representations can be used in a downstream task, to analyse how well the representations capture the input information. A simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c444e8-b6f8-472b-89c1-cf211f2f1034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "#transform_eeg = ContrastiveTransformations(device, probability_toZero=0.4)\n",
    "def gaussian_noise(X, std):\n",
    "      #https://github.com/braindecode/braindecode/blob/master/braindecode/augmentation/functional.py\n",
    "      \"\"\"Randomly add Gaussian noise to all channels.\n",
    "\n",
    "      Suggested e.g. in [1]_, [2]_ and [3]_\n",
    "\n",
    "      Parameters\n",
    "      ----------\n",
    "      X : torch.Tensor\n",
    "          EEG input example or batch.\n",
    "      y : torch.Tensor\n",
    "          EEG labels for the example or batch.\n",
    "      std : float\n",
    "          Standard deviation to use for the additive noise.\n",
    "\n",
    "      .. [1] Wang, F., Zhong, S. H., Peng, J., Jiang, J., & Liu, Y. (2018). Data\n",
    "        augmentation for eeg-based emotion recognition with deep convolutional\n",
    "        neural networks. In International Conference on Multimedia Modeling\n",
    "        (pp. 82-93).\n",
    "      .. [2] Cheng, J. Y., Goh, H., Dogrusoz, K., Tuzel, O., & Azemi, E. (2020).\n",
    "        Subject-aware contrastive learning for biosignals. arXiv preprint\n",
    "        arXiv:2007.04871.\n",
    "      .. [3] Mohsenvand, M. N., Izadi, M. R., & Maes, P. (2020). Contrastive\n",
    "        Representation Learning for Electroencephalogram Classification. In\n",
    "        Machine Learning for Health (pp. 238-253). PMLR.\n",
    "      \"\"\"\n",
    "      if not isinstance(X, torch.Tensor):\n",
    "          X = torch.tensor(X)\n",
    "          \n",
    "      noise = torch.normal(0, std, size=(X.shape)) #.to(device)\n",
    "      transformed_X = X + noise\n",
    "      return transformed_X\n",
    "        \n",
    "def create_tuple(x):\n",
    "    x1 = gaussian_noise(x, 0.4)\n",
    "    x2 = gaussian_noise(x, 0.1)\n",
    "    return (x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e0195a-61d7-47e1-970f-03324a52fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEED_IV\n",
    "\n",
    "    \n",
    "from torcheeg.datasets import SEEDIVFeatureDataset\n",
    "SEEDiv_dataset_path = os.path.join(TMP_DATA, 'SEEDiv_FE')\n",
    "SEEDivdataset = SEEDIVFeatureDataset(io_path=SEEDiv_dataset_path,\n",
    "                      root_path=SEEDiv_PATH,\n",
    "                      feature=['de_movingAve'],\n",
    "                      offline_transform=transforms.Compose([\n",
    "                                              transforms.BaselineRemoval(),\n",
    "                                              transforms.To2d(),\n",
    "                                              transforms.MeanStdNormalize(),\n",
    "                                              ]),\n",
    "                          online_transform=transforms.Compose([\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Lambda(lambda x: create_tuple(x)),\n",
    "                                                ]),\n",
    "                                          label_transform=transforms.Compose([\n",
    "                                              transforms.Select('emotion'),\n",
    "                                              transforms.Lambda(lambda x: x + 1)]),\n",
    "                                           num_worker=NUM_WORKERS\n",
    "                                          )\n",
    "print(SEEDivdataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0cd2b-7a70-42b6-a160-850994ceb3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(SEEDivdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8629669b-c3e1-4635-9d06-15798ad8e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "# Merge the datasets\n",
    "Combined_dataset = ConcatDataset([SEEDivdataset, SEEDivdataset2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a813e95-075e-417a-94f9-a51125058485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "test = 9\n",
    "validation = 3\n",
    "test_dataset = Datasets[test]\n",
    "val_dataset = Datasets[validation]\n",
    "train = [Datasets[i] for i in range(15) if i != test and i != validation]\n",
    "train_dataset = ConcatDataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb1a6bc7-ea2f-49e8-934d-a814e1715834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 35696\n",
      "Training Samples: 1879\n"
     ]
    }
   ],
   "source": [
    "train_FE_SSL, test_FE_SSL = sklearn.model_selection.train_test_split(SEEDivdataset, test_size=0.05, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
    "print(f'Training Samples: {len(train_FE_SSL)}')\n",
    "print(f'Training Samples: {len(test_FE_SSL)}')\n",
    "#print(f'First Sample : {train_FE_SSL[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1060e02-0a6e-4a2f-8df2-c49888e80b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FE_SSL[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85da67d7-434f-47df-9d92-c00c011ddbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FE_SSL1 = train_FE_SSL[:-7]\n",
    "print(f'new train len: {len(train_FE_SSL1)}')\n",
    "print(f'old test len: {len(test_FE_SSL)}')\n",
    "test_FE_SSL1 = ConcatDataset([train_FE_SSL[-7:], test_FE_SSL])\n",
    "print(f'new test len: {len(test_FE_SSL1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1774a8fa-c881-44b2-9816-52716b408c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "def train_simclr(model, num_samples, train_dataset, val_dataset, optimizer, temperature, lr, weight_decay, model_name = 'SimCLR', max_epochs=50, batch_size=100, embedding_dim=2048,feat_dim=128,logger=None, **kwargs):\n",
    "        \n",
    "    #default_root_dir=os.path.join(CHECKPOINT_PATH, 'version_0/'+'checkpoints/')\n",
    "    print(f'model: {model_name}, \\n default_root: {CHECKPOINT_PATH}')\n",
    "    \n",
    "    #Save Models in CHECKPOINT_PATH with model_name \n",
    "    save_model_callback = ModelCheckpoint(dirpath=CHECKPOINT_PATH,filename=model_name)\n",
    "    #Accumlate the gradients: in this case from 0-4 epoch it will accumlate 8 batches, from 5-8 it will accumlate 4 and finally 1\n",
    "    accumulator_callback = GradientAccumulationScheduler(scheduling={0: 8, 4: 4, 8: 1})\n",
    "    #EarlyStopping: stop and skip the rest of the current epoch when val_loss cant be reduced anymore\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "    #All Callsbacks:\n",
    "    callbacks = [save_model_callback, LearningRateMonitor(\"epoch\")]\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, model_name+'.ckpt')\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f'Found pretrained model at {pretrained_filename}, loading...')\n",
    "        # Automatically loads the model \n",
    "        ssl_model = SimCLR.load_from_checkpoint(pretrained_filename)\n",
    "        \n",
    "        print(f'Model loaded!')\n",
    "        \n",
    "    else:\n",
    "        print(f'No pretrained model at {pretrained_filename}, start training ...')\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "        '''\n",
    "        NOTE: The first element of each batch in :obj:`train_loader` and :obj:`val_loader` should be a two-tuple, representing two random transformations (views) of data. You can use :obj:`Contrastive` to achieve this functionality.\n",
    "        '''\n",
    " \n",
    "    \n",
    "        \n",
    "        ssl_model = SimCLR(model,\n",
    "                           accelerator= 'auto', #\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                           device='auto',\n",
    "                            gpus = 1, \n",
    "                            num_samples=num_samples,\n",
    "                            batch_size=batch_size,\n",
    "                            #dataset: str,\n",
    "                            num_nodes = 1,\n",
    "                            hidden_mlp= embedding_dim, #h(x): hidden_representation for downstream \n",
    "                            feat_dim= feat_dim, #z(x) projection_representation \n",
    "                            warmup_epochs= 10,\n",
    "                            max_epochs= max_epochs,\n",
    "                            temperature = temperature,\n",
    "                            rnoise = False,\n",
    "                            optimizer= optimizer,\n",
    "                            exclude_bn_bias = False,\n",
    "                            start_lr= 0.0,\n",
    "                            learning_rate= lr,\n",
    "                            final_lr= 0.0,\n",
    "                            weight_decay= weight_decay,\n",
    "                            )\n",
    "        \n",
    "        \n",
    "        ssl_model.fit(train_loader, val_loader, logger=logger, callbacks=callbacks)\n",
    "\n",
    "    return ssl_model, pretrained_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa944031-1ae7-45ab-8d8e-86dd138b2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSL_name='SSLExperiment_SeedIVOnly'\n",
    "logger = WandbLogger(log_model=\"all\", project=project_name, name=SSL_name)\n",
    "#model_name_path='./saved_models/SSLExperiment_SEEDIV_norm-v1.ckpt'\n",
    "model_name_path ='./saved_models/SSLExperiment_SeedIVOnly_augmented.ckpt'\n",
    "model_name = 'SSLExperiment_SeedIVOnly_Augmented'\n",
    "#pretrained_filename = os.path.join(CHECKPOINT_PATH, model_name+'.ckpt')\n",
    "#Save Models in CHECKPOINT_PATH with model_name \n",
    "save_model_callback = ModelCheckpoint(dirpath=CHECKPOINT_PATH,filename=model_name)\n",
    "#Accumlate the gradients: in this case from 0-4 epoch it will accumlate 8 batches, from 5-8 it will accumlate 4 and finally 1\n",
    "accumulator_callback = GradientAccumulationScheduler(scheduling={0: 8, 4: 4, 8: 1})\n",
    "#EarlyStopping: stop and skip the rest of the current epoch when val_loss cant be reduced anymore\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "#All Callsbacks:\n",
    "callbacks = [save_model_callback, accumulator_callback, LearningRateMonitor(\"epoch\")]\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_FE_SSL, batch_size=batch_sizeSSL, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(test_FE_SSL, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "ssl_model = SimCLR.load_from_checkpoint(model_name_path)\n",
    "ssl_model.fit(train_loader, val_loader, logger=logger, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52e7af3-5e77-48f1-b6f1-ec2e59a8644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb707860-46ea-447a-944a-fcb929b3b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSL_name='SSLExperiment_SeedIVOnly_augmented_GaussianNoise'\n",
    "wandb_logger = WandbLogger(log_model=\"all\", project=project_name, name=SSL_name)\n",
    "embedding_dim = 2048 #Embedding for Downstream\n",
    "feat_dim = 128 #Projection_head\n",
    "rnoise = False #With rolling Noise, if false, then GaussianNoise aus Augmentation\n",
    "\n",
    "'''\n",
    "TRAIN MODEL\n",
    "'''\n",
    "print(f'Start Training with Rnoise: {rnoise}, Epochs: {nr_epochs_ssl}, batch_size:{batch_sizeSSL}, embedding_dim: {embedding_dim}, lr: {lrSSL}, weight_decay:{weight_decaySSL}')\n",
    "\n",
    "'''\n",
    "model_ViT = ViT(chunk_size = 5,\n",
    "                     grid_size = (9, 9),\n",
    "                     t_patch_size = 1,\n",
    "                     s_patch_size = (3, 3),\n",
    "                     hid_channels = 32,\n",
    "                     depth=3,\n",
    "                     heads= 6,\n",
    "                     head_channels = 32,\n",
    "                     mlp_channels = 32,\n",
    "                     num_classes= embedding_dim,\n",
    "                     embed_dropout= 0.,\n",
    "                     dropout = 0.2,\n",
    "                     pool_func = 'cls')\n",
    "'''\n",
    "model_ViT   =    ArjunViT(chunk_size=5,\n",
    "                 t_patch_size=1,\n",
    "                 num_electrodes=channels,\n",
    "                 num_classes=embedding_dim)\n",
    "\n",
    "#A common observation in contrastive learning is that the larger the batch size, the better the models perform. A larger batch size allows us to compare each image to more negative examples, leading to overall smoother loss gradients.\n",
    "simclr_model, pretrained_filename = train_simclr(model =model_ViT,\n",
    "                                                num_samples = len(train_FE_SSL),\n",
    "                                                train_dataset = train_FE_SSL,\n",
    "                                                val_dataset = test_FE_SSL, \n",
    "                                                model_name = SSL_name,\n",
    "                                                max_epochs=nr_epochs_ssl,\n",
    "                                                batch_size=batch_sizeSSL,\n",
    "                                                embedding_dim=embedding_dim,\n",
    "                                                feat_dim=feat_dim, #For the projection_head \n",
    "                                                lr=lrSSL,\n",
    "                                                temperature=temperatureSSL,\n",
    "                                                weight_decay=weight_decaySSL,\n",
    "                                                rnoise = rnoise,\n",
    "                                                devices = 'auto',\n",
    "                                                logger=wandb_logger,\n",
    "                                                optimizer= \"lars\",\n",
    "                                                )\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a0a9af-48ea-4b7f-b34b-f0030d7b49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pretrained_filename)\n",
    "#print(pretrained_filename)\n",
    "#pretrained_filename = './saved_models/SSLExperiment_BIGData-v3.ckpt'\n",
    "pretrained_filename = './saved_models/SSLExperiment_SeedIVOnly_augmented_newRollingNoise-v2.ckpt'\n",
    "#pretrained_filename = './saved_models/SSLExperiment_SeedIVOnly_augmented_GaussianNoise-v1.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "508e8d62-a642-42a6-a7a2-2783446c984c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models/SSLExperiment_SeedIVOnly_augmented_newRollingNoise-v2.ckpt\n",
      "Found pretrained model at ./saved_models/SSLExperiment_SeedIVOnly_augmented_newRollingNoise-v2.ckpt, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "#AFTER TRAINING\n",
    "##Load Model_1 with weights and parameters:\n",
    "print(pretrained_filename)\n",
    "\n",
    "if os.path.isfile(pretrained_filename):\n",
    "        print(f'Found pretrained model at {pretrained_filename}, loading...')  \n",
    "        pretrained_ssl_model_1 = SimCLR.load_from_checkpoint(pretrained_filename)\n",
    "else:\n",
    "    print(f'No Model found') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47701c9f-abb0-44cb-af59-2756e6ac2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf './Tmp_Datasets/SEED_PATH_Subj8'\n",
    "#!rm -rf './Tmp_Datasets/SEED_PATH_Subj7'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31746d9-26c1-482c-97e5-14f19f08c5a2",
   "metadata": {},
   "source": [
    "## Downstream task\n",
    "\n",
    "The Pretext task was trained using contrastive learning with the Conformer as encoder, which creates vector representations of the eeg input. Those representations can be used in a downstream task, to analyse how well the representations capture the input information. A simple Logistic Regression can be used to classify the encoder vectors. For that we use the pretrained weights and create a new non-augmented Dataset. The non-augmented EEG samples are passed to the pretrained encoder to optain the input representations for the logistic Regression. The performance of the LR demonstrates how good the representations are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c037f-c442-40d0-9536-9a120dab3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave one out\n",
    "\n",
    "from torcheeg.datasets import SEEDFeatureDataset\n",
    "SEED_PATH_Subj = 'SEED_PATH_Subj'\n",
    "Datasets = []\n",
    "for i in range(1,16):\n",
    "    name = SEED_PATH_Subj + str(i)\n",
    "    file_path = SEED_PATH + str(i)\n",
    "    print(name)\n",
    "    \n",
    "    SEED_dataset_path = os.path.join(TMP_DATA, name)\n",
    "    Datasets.append(SEEDFeatureDataset(\n",
    "                      io_path=SEED_dataset_path, #location of loaded and transformed dataset\n",
    "                      root_path=file_path, #location of original dataset \n",
    "                      feature=['de_movingAve'],\n",
    "                      offline_transform=transforms.Compose([\n",
    "                                              transforms.BaselineRemoval(),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.To2d(),\n",
    "                                              transforms.MeanStdNormalize(),\n",
    "                                              ]),\n",
    "                                          label_transform=transforms.Compose([\n",
    "                                              transforms.Select('emotion'),\n",
    "                                              transforms.Lambda(lambda x: x + 1)]),\n",
    "                                           num_worker=NUM_WORKERS\n",
    "                                          ))\n",
    "print(Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120e323-db71-4672-9eaf-ec64a16abc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "subject_test_int = 15\n",
    "subject_train = 'train_AllSubj'\n",
    "subject_test = 'train_Subj'+str(subject_test_int)\n",
    "\n",
    "test_dataset = Datasets[subject_test_int-1]\n",
    "#val_dataset = Datasets[validation-1]\n",
    "train = [Datasets[i] for i in range(15) if i != subject_test_int-1]\n",
    "train_dataset = ConcatDataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698acef-b449-46b3-83da-9dfcb187a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b829e9c-20bb-465f-b11c-0b8427f2d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_info = !df -h\n",
    "disk_info = '\\n'.join(disk_info)\n",
    "print(disk_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc2e9cc-35aa-4592-af5e-c3a28624d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_ssl_model_1.projection.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce5413ff-0307-4045-aada-a35032036417",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataset):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model)\n",
    "    # Removing projection head g(.)\n",
    "    \n",
    "    for x in range(4):\n",
    "        network.projection.model[x]=nn.Identity()\n",
    "    \n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    # Encode all EEG samples by passing them through the pretrained SSL model\n",
    "    data_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    feats, labels = [], []\n",
    "    for batch_eegs, batch_labels in tqdm(data_loader):\n",
    "        batch_eegs = batch_eegs.squeeze()\n",
    "        #print(len(batch_imgs))\n",
    "        batch_eegs = batch_eegs.to(device)\n",
    "        batch_feats = network(batch_eegs)\n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    print(feats.shape)\n",
    "    feats = feats.unsqueeze(1) \n",
    "    print(feats.shape)\n",
    "\n",
    "    return TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d2d4c-7063-43f2-acbb-cad0e8ca65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate 1-D Feature Vector for Downstreamtask based on pretrained SSL-model\n",
    "train_feats_simclr = prepare_data_features(pretrained_ssl_model_1, train_dataset)\n",
    "val_feats_simclr = prepare_data_features(pretrained_ssl_model_1, test_dataset)\n",
    "#test_feats_simclr = prepare_data_features(pretrained_ssl_model_1, test_dataset)\n",
    "#print(f'generated features {train_feats_simclr}')\n",
    "torch.save(train_feats_simclr, os.path.join(DATA_PATH, subject_train))\n",
    "torch.save(val_feats_simclr, os.path.join(DATA_PATH, subject_test))\n",
    "#torch.save(test_feats_simclr, os.path.join(DATA_PATH, 'test_Leave1Out_Experiment2'))\n",
    "print(f'Saved to: {DATA_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a369e4a-4ad4-4bad-9a1f-d14a7efb974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(DATA_PATH, 'test_feats_simclr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b2ce8-c292-4536-8d32-39c4710e92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load generated features of normal non_augmented Data\n",
    "train_feats_simclr= torch.load(os.path.join(DATA_PATH, './'+subject_train))\n",
    "val_feats_simclr= torch.load(os.path.join(DATA_PATH, './'+subject_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3ced5-216f-488b-855e-77f571b377ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_feats_simclr= torch.load(os.path.join(DATA_PATH, './test_Leave1Out_Experiment2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fba9094-d24e-4721-b494-27920bffafe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised(model, batch_size, train_data, test_data, model_name, num_classes, logger=None,  max_epochs=100, **kwargs):\n",
    "    \n",
    "    \n",
    "    #Save Models in CHECKPOINT_PATH with model_name \n",
    "    save_model_callback = ModelCheckpoint(dirpath=CHECKPOINT_PATH,filename=model_name)\n",
    "    #Accumlate the gradients: in this case from 0-4 epoch it will accumlate 8 batches, from 5-8 it will accumlate 4 and finally 1\n",
    "    accumulator_callback = GradientAccumulationScheduler(scheduling={0: 8, 4: 4, 8: 1})\n",
    "    #EarlyStopping: stop and skip the rest of the current epoch when val_loss cant be reduced anymore\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "    \n",
    "    print(f'model: {model_name}, \\n default_root: {CHECKPOINT_PATH}')\n",
    "    trainer = pl.Trainer(\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices='auto',\n",
    "                         max_epochs=max_epochs,\n",
    "                         callbacks=[save_model_callback,\n",
    "                                    LearningRateMonitor(\"epoch\"),\n",
    "                                    accumulator_callback,\n",
    "                                    early_stop_callback,\n",
    "                                   ],\n",
    "                         #enable_progress_bar=False,\n",
    "                         check_val_every_n_epoch=5,\n",
    "                         logger=logger,\n",
    "                        )\n",
    "    \n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True,\n",
    "                                   drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False,\n",
    "                                  drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "    print(f'Batch_size: {batch_size}')\n",
    "    print(f'train_loader: {len(train_loader)}')\n",
    "\n",
    "    model = Trainer_class2(model, lr, weight_decay, max_epochs, num_classes)\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "    #model = Trainer_class2.load_from_checkpoint(pretrained_filename, model=model)\n",
    "    print(f'Done with model: {model_name}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3583f3-89b4-4825-9b17-cd847a585d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train with X number of samples per label instead of 100%: \n",
    "def get_smaller_dataset(original_dataset, num_eegs_per_label):\n",
    "    new_dataset = TensorDataset(\n",
    "        *[t.unflatten(0, (1, -1))[:,:num_eegs_per_label].flatten(0, 1) for t in original_dataset.tensors]\n",
    "    )\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3a5c6-bf11-4ed1-9e52-a71d071f36cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afa88db-c26d-4e64-af56-5bd808c16e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test the extraction of labels from the 'get_smaller_dataset' function\n",
    "Check, how many labels are returned\n",
    "'''\n",
    "print(f'Total Size of train_dataset: {len(train_feats_simclr)}')\n",
    "print(f'Total Size of test_dataset: {len(val_feats_simclr)}')\n",
    "\n",
    "print(f'Extract only portion of data samples per label')\n",
    "test = get_smaller_dataset(train_feats_simclr, 1425)\n",
    "print(len(test))\n",
    "print(f'One Sample is:')\n",
    "print(test[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640332e-c0e8-4b9a-ae0f-a09d7066445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Check label distribution of loaded data\n",
    "'''\n",
    "#Print Feature Infos of Data Samples \n",
    "train_t = train_feats_simclr.tensors[0]\n",
    "#test = test.unsqueeze(1)\n",
    "print(f'Training data: {train_t.shape}')\n",
    "feature_dim=train_feats_simclr.tensors[0].shape[2]\n",
    "list_labels_train = train_feats_simclr.tensors[1]\n",
    "list_labels_test = val_feats_simclr.tensors[1]\n",
    "print(f'Number of labels train: {len(list_labels_train)}, Number of labels test: {len(list_labels_test)}')\n",
    "# Get the unique values and their counts from the concatenated tensor\n",
    "unique_values_train, counts_train = torch.unique(list_labels_train, return_counts=True)\n",
    "print(f'unique Labels train: {unique_values_train}, Counts: {counts_train}')\n",
    "unique_values_test, counts_test = torch.unique(list_labels_test, return_counts=True)\n",
    "print(f'unique Labels test: {unique_values_test}, Counts: {counts_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dcc224-207c-43ba-b17a-8b5844f21095",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae77579-32d6-481d-9ecd-2e12cbddeccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "\n",
    "print(f'Start Training with Epochs: {nr_epochs}, nr_classes: {nr_classes}, batch_size:{batch_size}, lr: {lr}, weight_decay:{weight_decay}')\n",
    "\n",
    "#get 10%, 50% and 100% of the labels per sample:\n",
    "#_, counts_train = torch.unique(list_labels_train, return_counts=True)\n",
    "#percentages = [int(counts_train[0]*0.1), int(counts_train[0]*0.5), int(counts_train[0])]\n",
    "#print(f'train on using: {percentages} amount of labels')\n",
    "\n",
    "\n",
    "for subject_test_int in [1,2,3,15,13]:\n",
    "\n",
    "    name_ds = \"GausianNoise_DS_SEED_p\"+str(subject_test_int)\n",
    "    print(f'current model: {name_ds}')\n",
    "    \n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, name_ds+'-v1.ckpt')\n",
    "    print(pretrained_filename)\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f'Model {name_ds} already exist')\n",
    "        continue\n",
    "    else:\n",
    "        #wandb_logger = WandbLogger(log_model=\"all\", project=project_name, name=name_ds)\n",
    "    \n",
    "        subject_train = 'GausianNoise_train_AllSubj-'+str(subject_test_int)\n",
    "        subject_test = 'GausianNoise_train_Subj'+str(subject_test_int)\n",
    "        \n",
    "        test_dataset = Datasets[subject_test_int-1]\n",
    "        train = [Datasets[i] for i in range(15) if i != subject_test_int-1]\n",
    "        train_dataset = ConcatDataset(train)\n",
    "    \n",
    "        #Generate 1-D Feature Vector for Downstreamtask based on pretrained SSL-model\n",
    "        train_feats_simclr = prepare_data_features(pretrained_ssl_model_1, train_dataset)\n",
    "        val_feats_simclr = prepare_data_features(pretrained_ssl_model_1, test_dataset)\n",
    "        \n",
    "        #test_feats_simclr = prepare_data_features(pretrained_ssl_model_1, test_dataset)\n",
    "        #print(f'generated features {train_feats_simclr}')\n",
    "        torch.save(train_feats_simclr, os.path.join(DATA_PATH, subject_train))\n",
    "        torch.save(val_feats_simclr, os.path.join(DATA_PATH, subject_test))\n",
    "    \n",
    "        #Get feature Dimension \n",
    "        feature_dim=train_feats_simclr.tensors[0].shape[2]\n",
    "\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(in_features=feature_dim, out_features=nr_classes)  \n",
    "            )\n",
    "        \n",
    "        #Get only X-% of samples per label:\n",
    "        #sub_train_set = get_smaller_dataset(train_feats_simclr, num_eegs_per_label)\n",
    "\n",
    "\n",
    "        \n",
    "        print(f'Start Training on all, except subj: {subject_test_int}')\n",
    "        print(f'Model_name: {name_ds}')\n",
    "        \n",
    "        train_supervised(model = model, \n",
    "                        batch_size=batch_size,\n",
    "                        max_epochs=nr_epochs,\n",
    "                        train_data=train_feats_simclr,\n",
    "                        test_data=val_feats_simclr,\n",
    "                        model_name=f'{name_ds}',\n",
    "                        num_classes=nr_classes,\n",
    "                        lr=lr,\n",
    "                        weight_decay=weight_decay,\n",
    "                        logger = None,\n",
    "                        )\n",
    "        #wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cca6634-5958-4ecf-a46a-22934d8eda49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from torchmetrics import F1Score\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "def get_results_per_model(model, test_loader):\n",
    "\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    \n",
    "    # iterate over test data\n",
    "    for inputs, labels in test_loader:\n",
    "            #inputs = inputs.squeeze()\n",
    "            output = model.model(inputs) # Feedforward pass\n",
    "            output = output.squeeze()\n",
    "            output = torch.argmax(output, dim=1, keepdim=True).numpy()\n",
    "\n",
    "            y_pred.extend(output) # Save Prediction\n",
    "            \n",
    "            labels = labels.data.cpu().numpy()\n",
    "            y_true.extend(labels) # Save Truth\n",
    "\n",
    "    return y_pred,y_true\n",
    "\n",
    "def get_confusion_matrix(y_pred,y_true):\n",
    "    \n",
    "     # constant for classes\n",
    "    classes = ('Negative', 'Neutral', 'Positive')\n",
    "    \n",
    "    # Build confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                         columns = [i for i in classes])\n",
    "    plt.figure(figsize = (12,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.savefig(model_name+'_output.png')\n",
    "\n",
    "    #F1 Score:\n",
    "    f1 = F1Score(task=\"multiclass\", num_classes=3)\n",
    "    print('F1Score:')\n",
    "    y_pred = torch.tensor(y_pred).squeeze()\n",
    "    F1 = f1(y_pred,torch.tensor(y_true))\n",
    "    print(F1)\n",
    "    return F1, df_cm, cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56dac61-8865-49c4-9f4c-b345063dd090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#SSL DS:\n",
    "#[1,2,3,15,13]\n",
    "#Rolling Noise\n",
    "model_1 ='./saved_models/DS_SEED_p1-v1.ckpt'\n",
    "model_2 ='./saved_models/DS_SEED_p2-v1.ckpt'\n",
    "model_3 ='./saved_models/DS_SEED_p3-v1.ckpt'\n",
    "model_15 ='./saved_models/DS_SEED_p15-v1.ckpt'\n",
    "model_13 ='./saved_models/DS_SEED_p13-v1.ckpt'\n",
    "\n",
    "model_list = [model_1, model_2, model_3, model_15, model_13]\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "                     accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                     devices='auto',\n",
    "                     max_epochs=nr_epochs,\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "ypred_all = []\n",
    "\n",
    "\n",
    "mode = 'RollingNoise'\n",
    "\n",
    "\n",
    "for model_name in model_list:\n",
    "    print(f'model: {model_name[-15:]}')\n",
    "    try: \n",
    "        model = nn.Sequential(\n",
    "                            nn.Linear(in_features=2048, out_features=nr_classes)  \n",
    "                            )\n",
    "        model = Trainer_class2.load_from_checkpoint(model_name, model=model)\n",
    "        print(f'loaded model successfully')\n",
    "    \n",
    "    except Exception as e:\n",
    "        # If an exception occurs, print an error message\n",
    "        print(f\"Error loading model for {model_name}: {e}\")\n",
    "\n",
    "    #Get Test data    \n",
    "    try:\n",
    "        # Extract the number from the file name (get the integer between 'p' and '-v1').\n",
    "        extracted_number = int(re.search(r'p(\\d+)-v1', model_name).group(1))\n",
    "        print(f'extraced number: {extracted_number}')  \n",
    "        # Try to load the file\n",
    "        if mode == 'RollingNoise':\n",
    "            test_feats_simclr = torch.load(os.path.join(DATA_PATH, f'./train_Subj{extracted_number}')) #SSL_features_subj is a dataset\n",
    "        else:\n",
    "            test_feats_simclr = torch.load(os.path.join(DATA_PATH, f'./GausianNoise_train_Subj{extracted_number}'))\n",
    "    \n",
    "        print(f'Mode: {mode}')\n",
    "        \n",
    "        # If successful:\n",
    "        print(f\"File for Subject {extracted_number} loaded successfully.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        # If an exception occurs, print an error message\n",
    "        print(f\"Error loading file for Subject {model_name}: {e}\")\n",
    "    \n",
    "    \n",
    "    #Get feature Dimension \n",
    "    feature_dim=test_feats_simclr.tensors[0].shape[2]\n",
    "    \n",
    "    test_loader = DataLoader(test_feats_simclr, batch_size=batch_size, shuffle=False,\n",
    "                              drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "    # Test best model on test set\n",
    "    test_result = trainer.test(model, test_loader, verbose=False)\n",
    "    print(f'test_result: {test_result}')\n",
    "    y_pred,y_true = get_results_per_model(model, test_loader)\n",
    "    \n",
    "    F1, df_cm, cf_matrix = get_confusion_matrix(y_pred,y_true)\n",
    "    print(f'F1: {F1}')\n",
    "    print(f'df_cm: {df_cm}')\n",
    "    ypred_all.append(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb68aa-f0d0-4fcd-8614-ed12bce3f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#SSL DS:\n",
    "#[1,2,3,15,13]\n",
    "#Rolling Noise\n",
    "model_1 ='./saved_models/DS_SEED_p1-v1.ckpt'\n",
    "model_2 ='./saved_models/DS_SEED_p2-v1.ckpt'\n",
    "model_3 ='./saved_models/DS_SEED_p3-v1.ckpt'\n",
    "model_15 ='./saved_models/DS_SEED_p15-v1.ckpt'\n",
    "model_13 ='./saved_models/DS_SEED_p13-v1.ckpt'\n",
    "\n",
    "#AverageNoise\n",
    "\n",
    "model_1 = './saved_models/GausianNoise_DS_SEED_p1-v1.ckpt'\n",
    "model_2 = './saved_models/GausianNoise_DS_SEED_p2-v1.ckpt'\n",
    "model_3 = './saved_models/GausianNoise_DS_SEED_p3-v1.ckpt'\n",
    "model_15 = './saved_models/GausianNoise_DS_SEED_p15-v1.ckpt'\n",
    "model_13 = './saved_models/GausianNoise_DS_SEED_p13-v1.ckpt'\n",
    "\n",
    "\n",
    "model_list = [model_1, model_2, model_3, model_15, model_13]\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "                     accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                     devices='auto',\n",
    "                     max_epochs=nr_epochs,\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "ypred_all = []\n",
    "\n",
    "\n",
    "mode = 'GaussianNoise'\n",
    "\n",
    "\n",
    "for model_name in model_list:\n",
    "    print(f'model: {model_name[-15:]}')\n",
    "    try: \n",
    "        model = nn.Sequential(\n",
    "                            nn.Linear(in_features=2048, out_features=nr_classes)  \n",
    "                            )\n",
    "        model = Trainer_class2.load_from_checkpoint(model_name, model=model)\n",
    "        print(f'loaded model successfully')\n",
    "    \n",
    "    except Exception as e:\n",
    "        # If an exception occurs, print an error message\n",
    "        print(f\"Error loading model for {model_name}: {e}\")\n",
    "\n",
    "    #Get Test data    \n",
    "    try:\n",
    "        # Extract the number from the file name (get the integer between 'p' and '-v1').\n",
    "        extracted_number = int(re.search(r'p(\\d+)-v1', model_name).group(1))\n",
    "        print(f'extraced number: {extracted_number}')  \n",
    "        # Try to load the file\n",
    "        if mode == 'RollingNoise':\n",
    "            test_feats_simclr = torch.load(os.path.join(DATA_PATH, f'./train_Subj{extracted_number}')) #SSL_features_subj is a dataset\n",
    "        else:\n",
    "            test_feats_simclr = torch.load(os.path.join(DATA_PATH, f'./GausianNoise_train_Subj{extracted_number}'))\n",
    "    \n",
    "        print(f'Mode: {mode}')\n",
    "        \n",
    "        # If successful:\n",
    "        print(f\"File for Subject {extracted_number} loaded successfully.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        # If an exception occurs, print an error message\n",
    "        print(f\"Error loading file for Subject {model_name}: {e}\")\n",
    "    \n",
    "    \n",
    "    #Get feature Dimension \n",
    "    feature_dim=test_feats_simclr.tensors[0].shape[2]\n",
    "    \n",
    "    test_loader = DataLoader(test_feats_simclr, batch_size=batch_size, shuffle=False,\n",
    "                              drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "    # Test best model on test set\n",
    "    test_result = trainer.test(model, test_loader, verbose=False)\n",
    "    print(f'test_result: {test_result}')\n",
    "    y_pred,y_true = get_results_per_model(model, test_loader)\n",
    "    \n",
    "    F1, df_cm, cf_matrix = get_confusion_matrix(y_pred,y_true)\n",
    "    print(f'F1: {F1}')\n",
    "    print(f'df_cm: {df_cm}')\n",
    "    ypred_all.append(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b83f7-d5d3-471d-827e-3c96f4276359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the average of the DataFrames\n",
    "average_df = pd.concat(ypred_all).groupby(level=0).mean()\n",
    "print(f'Average over all k-folds: {average_df}')\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(average_df, annot=True)\n",
    "plt.savefig('Average_kfold_ds_GaussianNoise.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015aed7-87ef-4db5-91ad-b2f966898f3c",
   "metadata": {},
   "source": [
    "## Visualise Embeddings\n",
    "\n",
    "Visualise the embeddings of the self-supervised learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e816e-9f41-408f-a894-66f54be8e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load embeddings\n",
    "subject = 15\n",
    "SSL_features_subj = torch.load(os.path.join(DATA_PATH, f'./train_Subj{subject}'))\n",
    "print(SSL_features_subj[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa711886-8028-4891-8e02-8068bfd85d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Load one subject\n",
    "subject = 15\n",
    "subjectlist = [1,2,3,15,13]\n",
    "\n",
    "for subject in subjectlist:\n",
    "    print(f'model_name number: {subject}')\n",
    "    for mode in ['GaussianNoise', 'RollingNoise']:\n",
    "    \n",
    "        if mode == 'RollingNoise':\n",
    "            SSL_features_subj = torch.load(os.path.join(DATA_PATH, f'./train_Subj{subject}')) #SSL_features_subj is a dataset\n",
    "        else:\n",
    "            SSL_features_subj = torch.load(os.path.join(DATA_PATH, f'./GausianNoise_train_Subj{subject}'))\n",
    "    \n",
    "        print(f'Mode: {mode}')\n",
    "        # Extract training vectors and labels\n",
    "        train_vectors = []\n",
    "        labels = []\n",
    "        \n",
    "        for instance in SSL_features_subj:\n",
    "            train, label = instance\n",
    "            train_vectors.append(train.numpy().flatten())\n",
    "            labels.append(label)\n",
    "        \n",
    "        train_vectors = np.array(train_vectors)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # Apply t-SNE to the training vectors\n",
    "        tsne = TSNE(n_components=2, random_state=42)\n",
    "        train_vectors_tsne = tsne.fit_transform(train_vectors)\n",
    "        \n",
    "        # Create a scatter plot with colored points based on labels\n",
    "        plt.scatter(train_vectors_tsne[:, 0], train_vectors_tsne[:, 1], c=labels, cmap='viridis')\n",
    "        plt.title(f't-SNE Visualization of Subj-{subject} for {mode}')\n",
    "        plt.xlabel('t-SNE Component 1')\n",
    "        plt.ylabel('t-SNE Component 2')\n",
    "        plt.colorbar(label='Labels')\n",
    "        plt.show()\n",
    "        plt.savefig(f't-SNE_subj{subject}_{mode}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8837fd12-d593-4619-921f-1fff29de7d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=2048, out_features=128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_ssl_model_1.projection.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8097600-21df-47e6-ae1e-d9b8c8f292a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "\n",
    "print(f'Start Training with Epochs: {nr_epochs}, nr_classes: {nr_classes}, batch_size:{batch_size}, lr: {lr}, weight_decay:{weight_decay}')\n",
    "\n",
    "#get 10%, 50% and 100% of the labels per sample:\n",
    "#_, counts_train = torch.unique(list_labels_train, return_counts=True)\n",
    "#percentages = [int(counts_train[0]*0.1), int(counts_train[0]*0.5), int(counts_train[0])]\n",
    "#print(f'train on using: {percentages} amount of labels')\n",
    "\n",
    "\n",
    "for subject_test_int in [1,2,3,15,13]:\n",
    "\n",
    "    name_ds = \"FineTune_Rolling_DS_SEED_p\"+str(subject_test_int)\n",
    "    print(f'current model: {name_ds}')\n",
    "    \n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, name_ds+'-v1.ckpt')\n",
    "    print(pretrained_filename)\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f'Model {name_ds} already exist')\n",
    "        continue\n",
    "    else:\n",
    "        #wandb_logger = WandbLogger(log_model=\"all\", project=project_name, name=name_ds)\n",
    "\n",
    "        test_dataset = Datasets[subject_test_int-1]\n",
    "        train = [Datasets[i] for i in range(15) if i != subject_test_int-1]\n",
    "        train_dataset = ConcatDataset(train)\n",
    "\n",
    "        network = deepcopy(pretrained_ssl_model_1)\n",
    "        #Changing the last layer to [x, nr_classes]\n",
    "        network.projection.model[0]=nn.Linear(in_features=2048, out_features=nr_classes) \n",
    "        for x in range(1,4):\n",
    "            network.projection.model[x] == nn.Identity()\n",
    "            \n",
    "        print(f'Start Training on all, except subj: {subject_test_int}')\n",
    "        print(f'Model_name: {name_ds}')\n",
    "\n",
    "        train_supervised(model = network, \n",
    "                        batch_size=batch_size,\n",
    "                        max_epochs=nr_epochs,\n",
    "                        train_data=train_dataset,\n",
    "                        test_data=test_dataset,\n",
    "                        model_name=f'{name_ds}',\n",
    "                        num_classes=nr_classes,\n",
    "                        lr=lr,\n",
    "                        weight_decay=weight_decay,\n",
    "                        logger = None,\n",
    "                        )\n",
    "        #wandb.finish()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081bc179-a5b0-45ce-be8d-df7693a01f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform statisticall test\n",
    "from mlxtend.evaluate import mcnemar_table\n",
    "from mlxtend.evaluate import mcnemar\n",
    "import re\n",
    "\n",
    "#Load models that used rollingnoise\n",
    "model_1 ='./saved_models/DS_SEED_p1-v1.ckpt'\n",
    "model_2 ='./saved_models/DS_SEED_p2-v1.ckpt'\n",
    "model_3 ='./saved_models/DS_SEED_p3-v1.ckpt'\n",
    "model_15 ='./saved_models/DS_SEED_p15-v1.ckpt'\n",
    "model_13 ='./saved_models/DS_SEED_p13-v1.ckpt'\n",
    "\n",
    "model_list_rollingnoise = [model_1, model_2, model_3, model_15, model_13]\n",
    "\n",
    "#Load models that used GaussianNoise\n",
    "model_1_gn = './saved_models/GausianNoise_DS_SEED_p1-v1.ckpt'\n",
    "model_2_gn = './saved_models/GausianNoise_DS_SEED_p2-v1.ckpt'\n",
    "model_3_gn = './saved_models/GausianNoise_DS_SEED_p3-v1.ckpt'\n",
    "model_15_gn = './saved_models/GausianNoise_DS_SEED_p15-v1.ckpt'\n",
    "model_13_gn = './saved_models/GausianNoise_DS_SEED_p13-v1.ckpt'\n",
    "\n",
    "\n",
    "model_list_averagenoise = [model_1_gn, model_2_gn, model_3_gn, model_15_gn, model_13_gn]\n",
    "\n",
    "def get_results_per_model2(model, test_loader):\n",
    "\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    \n",
    "    # iterate over test data\n",
    "    for inputs, labels in test_loader:\n",
    "            inputs = inputs.squeeze()\n",
    "            inputs = inputs.to(device)\n",
    "            output = model.model(inputs) # Feedforward pass\n",
    "            output = output.squeeze()\n",
    "            output = torch.argmax(output.cpu(), dim=1, keepdim=True).numpy()\n",
    "\n",
    "            y_pred.extend(output) # Save Prediction\n",
    "            \n",
    "            labels = labels.data.cpu().numpy()\n",
    "            y_true.extend(labels) # Save Truth\n",
    "\n",
    "    return y_pred,y_true\n",
    "\n",
    "\n",
    "for rolling_noise_model, guassian_noise_model in zip(model_list_rollingnoise, model_list_averagenoise):\n",
    "    print('test models:')\n",
    "    print(rolling_noise_model)\n",
    "    print(guassian_noise_model)\n",
    "\n",
    "\n",
    "    #load model 1:\n",
    "    print(f'model: {rolling_noise_model[-15:]}')\n",
    "    extracted_number = int(re.search(r'p(\\d+)-v1', rolling_noise_model).group(1))\n",
    "    print(f'extraced number: {extracted_number}')\n",
    "    try: \n",
    "        model = nn.Sequential(\n",
    "                            nn.Linear(in_features=2048, out_features=nr_classes)  \n",
    "                            )\n",
    "        model = Trainer_class2.load_from_checkpoint(rolling_noise_model, model=model)\n",
    "        print(f'loaded model1 successfully')\n",
    "\n",
    "    except Exception as e:\n",
    "            # If an exception occurs, print an error message\n",
    "            print(f\"Error loading model for {rolling_noise_model}: {e}\")    \n",
    "\n",
    "    test_feats_rolling_noise = torch.load(os.path.join(DATA_PATH, f'./train_Subj{extracted_number}')) #SSL_features_subj is a dataset\n",
    "\n",
    "\n",
    "    #load model 2:\n",
    "    try: \n",
    "        model2 = nn.Sequential(\n",
    "                            nn.Linear(in_features=2048, out_features=nr_classes)  \n",
    "                            )\n",
    "        model2 = Trainer_class2.load_from_checkpoint(guassian_noise_model, model=model2)\n",
    "        print(f'loaded model2 successfully')\n",
    "\n",
    "    except Exception as e:\n",
    "            # If an exception occurs, print an error message\n",
    "            print(f\"Error loading model for {guassian_noise_model}: {e}\")\n",
    "    \n",
    "    test_feats_guassian_noise = torch.load(os.path.join(DATA_PATH, f'./GausianNoise_train_Subj{extracted_number}'))\n",
    "\n",
    "    #Get feature Dimension \n",
    "    #feature_dim=test_feats_guassian_noise.tensors[0].shape[2]\n",
    "        \n",
    "    test_loader_1 = DataLoader(test_feats_rolling_noise, batch_size=batch_size, shuffle=False,\n",
    "                                  drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    test_loader_2 = DataLoader(test_feats_guassian_noise, batch_size=batch_size, shuffle=False,\n",
    "                                  drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "    # Test best model on test set\n",
    "    y_pred1,y_true_1 = get_results_per_model2(model, test_loader_1)\n",
    "    y_pred2,y_true_2 = get_results_per_model2(model2, test_loader_2)\n",
    "\n",
    "    assert np.array_equal(y_true_1, y_true_2), \"y_true_2 is not the same as y_true_1\"   \n",
    "\n",
    "    y_true_1 = np.array(y_true_1)\n",
    "    y_pred1 = np.array(np.squeeze(y_pred1))\n",
    "    y_pred2 = np.array(np.squeeze(y_pred2))\n",
    "\n",
    "    tb = mcnemar_table(y_target=y_true_1, \n",
    "                   y_model1=y_pred1, \n",
    "                   y_model2=y_pred2)\n",
    "\n",
    "    \n",
    "    print(tb)\n",
    "    \n",
    "\n",
    "    chi2, p = mcnemar(ary=tb, corrected=True)\n",
    "    print('chi-squared:', chi2)\n",
    "    print('p-value:', p)    \n",
    "    if p < 0.05:\n",
    "        print('Models are significant different')\n",
    "    else:\n",
    "        print('Models are NOT significant different!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04685d09-6d23-48fe-9dc6-eafd4f166c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform statisticall test\n",
    "from mlxtend.evaluate import mcnemar_table\n",
    "from mlxtend.evaluate import mcnemar\n",
    "import re\n",
    "\n",
    "#Load models that used rollingnoise\n",
    "model_1 ='./saved_models/DS_SEED_p1-v1.ckpt'\n",
    "model_2 ='./saved_models/DS_SEED_p2-v1.ckpt'\n",
    "model_3 ='./saved_models/DS_SEED_p3-v1.ckpt'\n",
    "model_15 ='./saved_models/DS_SEED_p15-v1.ckpt'\n",
    "model_13 ='./saved_models/DS_SEED_p13-v1.ckpt'\n",
    "\n",
    "model_list_rollingnoise = [model_1, model_2, model_3, model_15, model_13]\n",
    "\n",
    "#Load models that used GaussianNoise\n",
    "model_1_bl = './saved_models/Basline_SEED_p1-v1.ckpt'\n",
    "model_2_bl = './saved_models/Basline_SEED_p2-v1.ckpt'\n",
    "model_3_bl = './saved_models/Basline_SEED_p3-v1.ckpt'\n",
    "model_15_bl = './saved_models/Basline_SEED_p15-v1.ckpt'\n",
    "model_13_bl = './saved_models/Basline_SEED_p13-v1.ckpt'\n",
    "\n",
    "\n",
    "model_list_baseline = [model_1_bl, model_2_bl, model_3_bl, model_15_bl, model_13_bl]\n",
    "\n",
    "def get_results_per_model2(model, test_loader):\n",
    "\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    \n",
    "    # iterate over test data\n",
    "    for inputs, labels in test_loader:\n",
    "            inputs = inputs.squeeze()\n",
    "            inputs = inputs.to(device)\n",
    "            output = model.model(inputs) # Feedforward pass\n",
    "            output = output.squeeze()\n",
    "            output = torch.argmax(output.cpu(), dim=1, keepdim=True).numpy()\n",
    "\n",
    "            y_pred.extend(output) # Save Prediction\n",
    "            \n",
    "            labels = labels.data.cpu().numpy()\n",
    "            y_true.extend(labels) # Save Truth\n",
    "\n",
    "    return y_pred,y_true\n",
    "\n",
    "\n",
    "for rolling_noise_model, baseline_model in zip(model_list_rollingnoise, model_list_baseline):\n",
    "    print('test models:')\n",
    "    print(rolling_noise_model)\n",
    "    print(baseline_model)\n",
    "\n",
    "\n",
    "    #load model 1:\n",
    "    print(f'model: {rolling_noise_model[-15:]}')\n",
    "    extracted_number = int(re.search(r'p(\\d+)-v1', rolling_noise_model).group(1))\n",
    "    print(f'extraced number: {extracted_number}')\n",
    "    try: \n",
    "        model = nn.Sequential(\n",
    "                            nn.Linear(in_features=2048, out_features=nr_classes)  \n",
    "                            )\n",
    "        model = Trainer_class2.load_from_checkpoint(rolling_noise_model, model=model)\n",
    "        print(f'loaded model1 successfully')\n",
    "\n",
    "    except Exception as e:\n",
    "            # If an exception occurs, print an error message\n",
    "            print(f\"Error loading model for {rolling_noise_model}: {e}\")    \n",
    "\n",
    "    test_feats_rolling_noise = torch.load(os.path.join(DATA_PATH, f'./train_Subj{extracted_number}')) #SSL_features_subj is a dataset\n",
    "\n",
    "\n",
    "    #load model 2:\n",
    "    try: \n",
    "        model2 = nn.Sequential(\n",
    "                            nn.Linear(in_features=2048, out_features=nr_classes)  \n",
    "                            )\n",
    "        model2 = Trainer_class2.load_from_checkpoint(baseline_model, model=model2)\n",
    "        print(f'loaded model2 successfully')\n",
    "\n",
    "    except Exception as e:\n",
    "            # If an exception occurs, print an error message\n",
    "            print(f\"Error loading model for {baseline_model}: {e}\")\n",
    "    \n",
    "    test_feats_guassian_noise = torch.load(os.path.join(DATA_PATH, f'./GausianNoise_train_Subj{extracted_number}'))\n",
    "\n",
    "    #Get feature Dimension \n",
    "    #feature_dim=test_feats_guassian_noise.tensors[0].shape[2]\n",
    "        \n",
    "    test_loader_1 = DataLoader(test_feats_rolling_noise, batch_size=batch_size, shuffle=False,\n",
    "                                  drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    test_loader_2 = DataLoader(test_feats_guassian_noise, batch_size=batch_size, shuffle=False,\n",
    "                                  drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "    # Test best model on test set\n",
    "    y_pred1,y_true_1 = get_results_per_model2(model, test_loader_1)\n",
    "    y_pred2,y_true_2 = get_results_per_model2(model2, test_loader_2)\n",
    "\n",
    "    assert np.array_equal(y_true_1, y_true_2), \"y_true_2 is not the same as y_true_1\"   \n",
    "\n",
    "    y_true_1 = np.array(y_true_1)\n",
    "    y_pred1 = np.array(np.squeeze(y_pred1))\n",
    "    y_pred2 = np.array(np.squeeze(y_pred2))\n",
    "\n",
    "    tb = mcnemar_table(y_target=y_true_1, \n",
    "                   y_model1=y_pred1, \n",
    "                   y_model2=y_pred2)\n",
    "\n",
    "    \n",
    "    print(tb)\n",
    "    \n",
    "\n",
    "    chi2, p = mcnemar(ary=tb, corrected=True)\n",
    "    print('chi-squared:', chi2)\n",
    "    print('p-value:', p)    \n",
    "    if p < 0.05:\n",
    "        print('Models are significant different')\n",
    "    else:\n",
    "        print('Models are NOT significant different!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
